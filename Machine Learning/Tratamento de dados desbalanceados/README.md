# ğŸŒ² Tratamento de Dados Desbalanceados â€” Cobertura Vegetal

Este projeto tem como objetivo aplicar tÃ©cnicas de balanceamento de dados â€” **subamostragem com Tomek Links** e **sobreamostragem com SMOTE** â€” utilizando uma base de dados de tipos de cobertura vegetal. O projeto foi desenvolvido em Python, com foco em experimentaÃ§Ã£o e avaliaÃ§Ã£o do impacto das tÃ©cnicas sobre um modelo de classificaÃ§Ã£o.

---

## ğŸ“ Estrutura do Projeto


â”œâ”€â”€ cover_type.csv
â””â”€â”€ cover_type.pkl
â””â”€â”€ dados.ipynb
â””â”€â”€ README.md

---

## ğŸ“Œ Objetivos

- Visualizar o desbalanceamento entre classes da base.
- Aplicar subamostragem com **Tomek Links**.
- Aplicar sobreamostragem com **SMOTE**.
- Treinar um **RandomForestClassifier** com os dados balanceados.
- Avaliar a acurÃ¡cia e o relatÃ³rio de classificaÃ§Ã£o dos modelos.

---

## ğŸ“Š DescriÃ§Ã£o da Base

A base utilizada contÃ©m atributos sobre regiÃµes geogrÃ¡ficas e seu respectivo tipo de cobertura vegetal. A variÃ¡vel-alvo Ã© a coluna `Cover_Type`, com mÃºltiplas classes (multiclasse).  

O arquivo `.csv` contÃ©m os dados brutos e o arquivo `.pkl` contÃ©m os dados jÃ¡ prÃ©-processados.

---

## ğŸ” AnÃ¡lise Inicial

- A variÃ¡vel `Cover_Type` foi analisada com `value` e com grÃ¡fico de barras via Seaborn.
- A distribuiÃ§Ã£o revelou forte desbalanceamento entre as classes.

---

## âš™ï¸ Subamostragem com Tomek Links

- Utilizamos `TomekLinks(sampling_strategy="all")` apenas sobre os dados de **treinamento**.
- As classes majoritÃ¡rias foram reduzidas ao remover pares Tomek.
- ApÃ³s a subamostragem:
  - Algumas classes foram mais bem representadas.
  - Outras perderam muitos exemplos.

### ğŸ§  Treinamento

- Modelo: `RandomForestClassifier`
- AcurÃ¡cia: **ligeiramente menor** que a versÃ£o sem balanceamento (80.64%).

---

## ğŸ” Sobreamostragem com SMOTE

- Utilizamos `SMOTE(sampling_strategy="auto")`, que gera novas amostras para todas as classes **menos a majoritÃ¡ria**.
- Isso equilibra a base sem remover exemplos reais.

### ğŸ§  Treinamento

- Modelo: `RandomForestClassifier`
- AcurÃ¡cia: **similar** Ã  versÃ£o original.
- O recall das classes minoritÃ¡rias aumentou, embora a precisÃ£o tenha diminuÃ­do.

---


## ğŸ“š Bibliotecas Utilizadas

- `pandas`, `numpy`
- `matplotlib`, `seaborn`
- `scikit-learn`
- `imblearn`

---

## ğŸ“ ConclusÃ£o

Tanto o SMOTE quanto o Tomek Links mostraram impacto na performance do modelo, especialmente nas **mÃ©tricas por classe**. O uso dessas tÃ©cnicas Ã© essencial quando lidamos com bases de dados desbalanceadas, principalmente em problemas multiclasse.

---

## ğŸ‘¨â€ğŸ’» Autor

Matheus â€” Estudante de AnÃ¡lise e Desenvolvimento de Sistemas, com foco em CiÃªncia de Dados.
