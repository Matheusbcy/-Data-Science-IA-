# ğŸŒ³ SeleÃ§Ã£o de Atributos  

## ğŸ“˜ DescriÃ§Ã£o

Este exercÃ­cio teve como foco a aplicaÃ§Ã£o de tÃ©cnicas de **seleÃ§Ã£o de atributos** com o objetivo de melhorar o desempenho de algoritmos de classificaÃ§Ã£o e reduzir a dimensionalidade dos dados. Foram utilizadas duas abordagens principais: **eliminaÃ§Ã£o por baixa variÃ¢ncia** e **seleÃ§Ã£o baseada na importÃ¢ncia dos atributos** com o modelo `ExtraTreesClassifier`.

## ğŸ“‚ Base de Dados

A base utilizada foi a de **cobertura vegetal**, previamente tratada em exercÃ­cios anteriores. Para esta etapa:

- Foram removidas as **colunas categÃ³ricas**, pois o mÃ©todo de variÃ¢ncia Ã© voltado para atributos numÃ©ricos.
- O conjunto de dados foi escalado com `MinMaxScaler`.
- A variÃ¡vel alvo foi codificada com `LabelEncoder`.

## ğŸ§ª Etapas do ExercÃ­cio

### ğŸ”¹ PreparaÃ§Ã£o dos Dados

- Leitura da base de dados.
- RemoÃ§Ã£o das trÃªs Ãºltimas colunas (duas categÃ³ricas + variÃ¡vel alvo).
- SeparaÃ§Ã£o das variÃ¡veis independentes (`X`) e dependentes (`y`).
- AplicaÃ§Ã£o do escalonamento (`MinMaxScaler`) e codificaÃ§Ã£o (`LabelEncoder`).
- Salvamento das variÃ¡veis `X` e `y` para uso posterior.

---

### ğŸ”¸ SeleÃ§Ã£o por VariÃ¢ncia

- CÃ¡lculo da variÃ¢ncia de cada atributo numÃ©rico.
- AplicaÃ§Ã£o do `VarianceThreshold` com `threshold=0.02`.
- VerificaÃ§Ã£o de quais atributos foram mantidos.
- SeparaÃ§Ã£o dos dados em treino e teste.
- Treinamento de um `RandomForestClassifier`.
- AvaliaÃ§Ã£o do desempenho com mÃ©tricas de acurÃ¡cia.

ğŸ“‰ Resultado: o modelo teve desempenho inferior ao modelo treinado com todos os atributos, indicando que atributos de baixa variÃ¢ncia e atÃ© mesmo os categÃ³ricos excluÃ­dos possuem valor preditivo.

---

### ğŸ”¸ SeleÃ§Ã£o por ImportÃ¢ncia com ExtraTreesClassifier

- Treinamento de um `ExtraTreesClassifier` com todos os atributos para avaliaÃ§Ã£o da importÃ¢ncia de cada um.
- SeleÃ§Ã£o dos atributos com importÃ¢ncia superior a `0.07`.
- Filtragem da base `X` com base nesses atributos.
- SeparaÃ§Ã£o dos dados em treino e teste.
- Novo treinamento com `RandomForestClassifier`.
- AvaliaÃ§Ã£o da acurÃ¡cia.

ğŸ“ˆ Resultado: o desempenho foi **melhor do que o modelo baseado em variÃ¢ncia**, porÃ©m **ainda inferior ao modelo com todos os atributos**.

---

## âœ… ConclusÃ£o

A seleÃ§Ã£o de atributos pode ajudar a reduzir a dimensionalidade, simplificar modelos e reduzir overfitting. No entanto, neste caso especÃ­fico:

- **A seleÃ§Ã£o por variÃ¢ncia removeu atributos importantes**, resultando em perda de desempenho.
- **A seleÃ§Ã£o por importÃ¢ncia se saiu melhor**, mas ainda **nÃ£o superou o uso da base completa**.

Esse exercÃ­cio mostra que a reduÃ§Ã£o de dimensionalidade deve ser feita com critÃ©rio, e nem sempre menos atributos resultam em modelos melhores.

## ğŸ‘¨â€ğŸ’» Autor

Matheus â€” Estudante de AnÃ¡lise e Desenvolvimento de Sistemas, com foco em CiÃªncia de Dados.
